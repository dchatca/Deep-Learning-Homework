{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f985d80",
   "metadata": {},
   "source": [
    "# Nguyễn Ngọc Đạt - 11200745 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1fcb2f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import arange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from matplotlib import pyplot\n",
    "from numpy import asarray\n",
    "from numpy.random import rand\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf727e7",
   "metadata": {},
   "source": [
    "### Bài 1:\n",
    "\n",
    "### Cho phương trình f(x)= x^2, hãy sử dụng thuật toán gradient descent để tối ưu. Sau đó vẽ đồ thị hàm f(x) sau 10 lần cập nhật bước 2 với:\n",
    "### * Lr = 0.2\n",
    "### * Lr = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b132b058",
   "metadata": {},
   "source": [
    "### Gradient descent function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ca5f9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# objective function\n",
    "def objective(x):\n",
    "    return x**2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4a58837a",
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "# define range for input\n",
    "r_min, r_max = -1.0, 1.0\n",
    "# sample input range uniformly at 0.1 increments\n",
    "inputs = arange(r_min, r_max+0.1, 0.1)\n",
    "# compute targets\n",
    "results = objective(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ad3496b",
   "metadata": {
    "hide_input": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a line plot of input vs result\n",
    "pyplot.plot(inputs, results)\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5ae29100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# derivative of objective function\n",
    "def derivative(x):\n",
    "    return x * 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e1dc5624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12913668])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = asarray([[-1.0, 1.0]])\n",
    "bounds[:,1]\n",
    "rand(len(bounds)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5b228f",
   "metadata": {},
   "source": [
    "### Lr = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cedb71c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0 f([0.11980163]) = 0.01435\n",
      ">1 f([0.07188098]) = 0.00517\n",
      ">2 f([0.04312859]) = 0.00186\n",
      ">3 f([0.02587715]) = 0.00067\n",
      ">4 f([0.01552629]) = 0.00024\n",
      ">5 f([0.00931577]) = 0.00009\n",
      ">6 f([0.00558946]) = 0.00003\n",
      ">7 f([0.00335368]) = 0.00001\n",
      ">8 f([0.00201221]) = 0.00000\n",
      ">9 f([0.00120732]) = 0.00000\n",
      ">10 f([0.00072439]) = 0.00000\n",
      ">11 f([0.00043464]) = 0.00000\n",
      ">12 f([0.00026078]) = 0.00000\n",
      ">13 f([0.00015647]) = 0.00000\n",
      ">14 f([9.38815459e-05]) = 0.00000\n",
      ">15 f([5.63289276e-05]) = 0.00000\n",
      ">16 f([3.37973565e-05]) = 0.00000\n",
      ">17 f([2.02784139e-05]) = 0.00000\n",
      ">18 f([1.21670484e-05]) = 0.00000\n",
      ">19 f([7.30022901e-06]) = 0.00000\n",
      ">20 f([4.38013741e-06]) = 0.00000\n",
      ">21 f([2.62808244e-06]) = 0.00000\n",
      ">22 f([1.57684947e-06]) = 0.00000\n",
      ">23 f([9.4610968e-07]) = 0.00000\n",
      ">24 f([5.67665808e-07]) = 0.00000\n",
      ">25 f([3.40599485e-07]) = 0.00000\n",
      ">26 f([2.04359691e-07]) = 0.00000\n",
      ">27 f([1.22615815e-07]) = 0.00000\n",
      ">28 f([7.35694887e-08]) = 0.00000\n",
      ">29 f([4.41416932e-08]) = 0.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# gradient descent algorithm\n",
    "def gradient_descent(objective, derivative, bounds, n_iter, step_size):\n",
    "    # track all solutions\n",
    "    solutions, scores = list(), list()\n",
    "    # generate an initial point\n",
    "    #solution = bounds[:, 0] + rand(len(bounds)) * (bounds[:, 1] - bounds[:, 0])\n",
    "    solution = rand(len(bounds))\n",
    "    for i in range(n_iter):\n",
    "        # calculate gradient\n",
    "        gradient = derivative(solution)\n",
    "        # take a step\n",
    "        solution = solution - step_size * gradient\n",
    "        # evaluate candidate point\n",
    "        solution_eval = objective(solution)\n",
    "        # store solution\n",
    "        solutions.append(solution)\n",
    "        scores.append(solution_eval)\n",
    "        # report progress\n",
    "        print('>%d f(%s) = %.5f' % (i, solution, solution_eval))\n",
    "    return [solutions, scores]\n",
    "\n",
    "# define range for input\n",
    "bounds = asarray([[-1.0, 1.0]])\n",
    "# define the total iterations\n",
    "n_iter = 30\n",
    "# define the step size\n",
    "step_size = 0.2\n",
    "# perform the gradient descent search\n",
    "solutions, scores = gradient_descent(objective, derivative, bounds, n_iter, step_size)\n",
    "# sample input range uniformly at 0.1 increments\n",
    "inputs = arange(bounds[0,0], bounds[0,1]+0.1, 0.1)\n",
    "# compute targets\n",
    "results = objective(inputs)\n",
    "# create a line plot of input vs result\n",
    "pyplot.plot(inputs, results)\n",
    "# plot the solutions found\n",
    "pyplot.plot(solutions, scores, '.-', color='red')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31560c6",
   "metadata": {},
   "source": [
    "### Lr = 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ad3298c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0 f([-0.66413171]) = 0.44107\n",
      ">1 f([1.99239512]) = 3.96964\n",
      ">2 f([-5.97718537]) = 35.72674\n",
      ">3 f([17.93155612]) = 321.54070\n",
      ">4 f([-53.79466837]) = 2893.86634\n",
      ">5 f([161.38400511]) = 26044.79710\n",
      ">6 f([-484.15201532]) = 234403.17393\n",
      ">7 f([1452.45604595]) = 2109628.56541\n",
      ">8 f([-4357.36813784]) = 18986657.08866\n",
      ">9 f([13072.10441352]) = 170879913.79790\n",
      ">10 f([-39216.31324055]) = 1537919224.18110\n",
      ">11 f([117648.93972166]) = 13841273017.62994\n",
      ">12 f([-352946.81916497]) = 124571457158.66943\n",
      ">13 f([1058840.45749491]) = 1121143114428.02515\n",
      ">14 f([-3176521.37248472]) = 10090288029852.22656\n",
      ">15 f([9529564.11745417]) = 90812592268670.03125\n",
      ">16 f([-28588692.3523625]) = 817313330418030.25000\n",
      ">17 f([85766077.05708751]) = 7355819973762273.00000\n",
      ">18 f([-2.57298231e+08]) = 66202379763860456.00000\n",
      ">19 f([7.71894694e+08]) = 595821417874744192.00000\n",
      ">20 f([-2.31568408e+09]) = 5362392760872696832.00000\n",
      ">21 f([6.94705224e+09]) = 48261534847854272512.00000\n",
      ">22 f([-2.08411567e+10]) = 434353813630688428032.00000\n",
      ">23 f([6.25234702e+10]) = 3909184322676195328000.00000\n",
      ">24 f([-1.87570411e+11]) = 35182658904085760049152.00000\n",
      ">25 f([5.62711232e+11]) = 316643930136771844636672.00000\n",
      ">26 f([-1.68813369e+12]) = 2849795371230946534621184.00000\n",
      ">27 f([5.06440108e+12]) = 25648158341078516127236096.00000\n",
      ">28 f([-1.51932033e+13]) = 230833425069706627965255680.00000\n",
      ">29 f([4.55796098e+13]) = 2077500825627360029644423168.00000\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "solutions, scores = gradient_descent(objective, derivative, bounds, n_iter, 2)\n",
    "# sample input range uniformly at 0.1 increments\n",
    "inputs = arange(bounds[0,0], bounds[0,1]+0.1, 0.1)\n",
    "# compute targets\n",
    "results = objective(inputs)\n",
    "# create a line plot of input vs result\n",
    "pyplot.plot(inputs, results)\n",
    "# plot the solutions found\n",
    "pyplot.plot(solutions, scores, '.-', color='red')\n",
    "# show the plot\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb75045",
   "metadata": {},
   "source": [
    "### Bài 2: \n",
    "### Cho dataset dự đoán giá nhà dựa vào diện tích (https://github.com/nttuan8/DL_Tutorial/blob/master/L1/data_linear.csv) Dựa vào code mẫu hãy\n",
    "### * Implement thuật toán linear regression với dữ liệu trên\n",
    "### * Chỉnh learning rate cho dữ liệu trên, chọn 1 learning rate lớn bị overshoot, 1 learning vừa, và 1 learning rate nhỏ. Với mỗi learning rate, vẽ đồ thị loss tương ứng\n",
    "### * Chia tập train/test tỉ lệ 80/20, tính các chỉ số MSE, RSME, MAE, MAPE trên tập test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d6da4b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data_linear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1664df20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diện tích</th>\n",
       "      <th>Giá</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.0000</td>\n",
       "      <td>448.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4138</td>\n",
       "      <td>509.248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34.8276</td>\n",
       "      <td>535.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37.2414</td>\n",
       "      <td>551.432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39.6552</td>\n",
       "      <td>623.418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diện tích      Giá\n",
       "0    30.0000  448.524\n",
       "1    32.4138  509.248\n",
       "2    34.8276  535.104\n",
       "3    37.2414  551.432\n",
       "4    39.6552  623.418"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a140613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 2)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "bd00bbc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEXCAYAAABcRGizAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAhOUlEQVR4nO3de7hcdX3v8feHBALhEggJEnLbaCNKABF2AbVFJAhogaAtGhoOAalRD4jR9ihpzhF5anoUPUrVAzZFDGKERmo1oiAYFUURGm6GBFICyU4CgYRbDogHIXz7x/rtsBjmujP3+byeZz975rfWrPWd2bPnO7/rUkRgZmZWzg6tDsDMzNqfk4WZmVXkZGFmZhU5WZiZWUVOFmZmVpGThZmZVeRkYUMmaa2k4yrsM0vSZknHbMd5Zkq6MXd/N0n/KelySadIOn+oxy5yrl9I+pti501lb5S0TtKn63XO3LFPkXSbpJ3K7PMZSd+u0/nOknRLme2jJT0g6dA6nOsTkr5bh+P8uaRVRcr3lPSQpDdvx7HLvp/r9Rw6lZNFh0n/4MslPSfpUUmXShrV6riKkfQG4P3AgcCnJO0+lONExKKIOD5XdAhwObAMmAcs2d5YqzmvpF2ArwJ/DrxO0mFDOa6kPkkhaXiubG/gH4HTIuKP2xl6XUTEk8DpwGX5WId4rC8BkvSX23mcX0XEAUU2fQn4x4i4a3uOX+HcdXkOncrJooNI+lvg88D/AEYBRwF9wI2SdmxhaEVFxP0R8e6I2BwR74qIZ+p03N9ExMUR8fWIODIi1gJIWlCP45c57x8i4riIGIiIWRFxZx0PPxWYHRHr6njM7RYRy4D5wJ/U4XAfAMbU4TivkL6E3B4Rl9f72EU05Dl0AieLDiFpD+Ai4KMRcUNEvJA+JN8H7A/8ddpvoaTP5h53jKQNufsXSHpQ0jOSVkp6T27bWZJukfRFSU9JWiPpXRVCO1TS7yRtkfSvknbOHe8kSXdLelrSbyQdUub5HS9pVTrOpZJuzjUHbWsuKfGtPFKz0OslvU7SzyQ9IelxSYsk7VnmvO+UdH8679cAFb4euftvkHSTpCdTrO/LbVso6f9K+lF6bW+T9LoSp/1l+v20pGclvQV4LXBx7nhTc+d6TNLf5x6/k6RvpfOskNRf5vmFpA+n5qSnUowq2Kfo31vS2ZLuA64GfizpQyXOMSL9jQ/KlY2V9AdJ+0jaS9J1wIPA5yRdJ2lCmZgPk3RXen7fTe+rz6Ztr3o/A3cDXyh8Pxc57mckLa7w2hV9P9f6HLqRk0XneCuwM/C9fGFEPAtcDxxf7EFFPEjWjDKKLPl8W9K43PYjgVVk354uBr5R+OFS4H3AiWQJ6xDgLMj+4YErgA8BewP/DCyRNKLwAJLGANcCc9O+q9Lzrdaj6bncSfZh/7+B/YA3AhOBzxR7UDrvvwH/k+z5Pgi8rcS+uwI3Ad8B9iFrnrlU0tTcbqenOPYCVpN9Iy/m6PR7z4jYLSJuLTjX7sBPgRvS8/gTYGlul1OAa4A9yZrgvlbiPINOAv4UeBPZ3+uE3LZyf+9N6bF7AGcDX1aRpreIeJ7sfXl6rvh9wM0RsYnsc+abwGRgEvCHUjEr66/5d2AhMJosUZVMAMAastez1Pu5UKXXruj7uZbn0LUiwj8d8AOcATxaYtvngBvT7YXAZ3PbjgE2lDnu3cD0dPssYHVu20gggH1LPHYtcEbu/sXA19Pty4B/KNh/FfD2Isc5E7g1d1/AeuBvcnHdkm73pZiG5/b/xeC+RY59KnBXiW1nAr8tOO+GEud9P/Crgsf/M3Bh7nW/PLft3cD9Jc5b7Dnkz3V6mZg/A/w0d/9A4A9l/r4B/Fnu/mLggiH+vb8PfKzEtuOAh3L3fw2cWWLfQ4GnSmw7GngYUK7sFtJ7mhrez7W+dpR5P9fyHLr1Z7s6raypHgfGSBoeES8WbBsHbK7mIJLOBD5B9oEFsBuvbIN9dPBGRDyXvmTuVuaQj+ZuP0f2TRiyb2CzJH00t32n3Pa8/ciSw+B5I9/UUAtJ+wBfIas97U72jfCpErsXO+/6EvtOBo6U9HSubDhwVe5+4WtR7nUrZyJZLaeUwvPsXOJ9UU1cJf/eqUnqQuD1ZK/jSGB5iXP8DNhF0pHpmIeS1RCQNBL4Mtk39r3S/rtLGhYRWwuOsx/wcKRP5KTU3wRJ7wc+DowHtgL7Ur5PodJrV/T9XONz6EpuhuoctwLPA+/NF6bmkXcBN6ei35P9Uw/aN7fvZOBfgPOAvSNiT+Becu30dbQemB8Re+Z+RkbE1UX23Qhsa/9NzSCl2oN/n34XfY5kTVABHBIRe5DVyEo9v41kH8z5804sse96smaV/PPZLSI+UmL/ciot9bweKNXf0RSpufDfgC8Cr0nvlR9T4rWMiJfIai2nk/WfXRcvD2j4W+AA4Mj0Nxlshit2rI3A+IKmz6J/E0kTyWp050XExIjoI6u9NuL9XMtz6EpOFh0iIraQtcl+VdKJknaU1Ad8l6zWsSjtejfwbmVj5PcF5uQOsyvZB9VmyDowgYNojH8BPizpSGV2lfQXKj589kfAwZJOVdZxfS6vTADbRMRmsmaKMyQNk/QBXjlSZ3fgWbLO4/FkI8dK+REwVdJ703nPL3Ve4DqyDvT/ll77HSX9qaQ3ljl+KZuBl8g6tUuda19Jc1Ln8e7pG3sz7QSMIIv1xVTLqNQv9h2y5rqZ6fag3cna+J+WNJqstlLKrWQ1hPMkDZc0HTiixL57kH1Y/z69F84mG1XWCLU8h67kZNFBIuJi4O/Jvu09Q9a5NxI4LiIGv3FfBdxD1v56I/CvucevBP4P2T/kY8DBZG3LjYh1GfBBsk7Ap8g6fM8qse/jwGlkbcRPkLUlLyOrSRXzQbIk8ARZp23+OVwEHAZsIUsG33vVo1993s+lY02hxOuRviUfD8wAHiFrrvg82QdqTSLiObLO71+nUURHFTnXO4GT03keAN5R63m2R4rhfLLawlNktYWy81ki4jaymt9+ZIMuBl0C7EL2pea3ZB33pY7xR7La8znA02Q1w+so8l6IiBVk7+df0+D3MzU8h26lVzYNWidJ36ovAt4WbTY+f3tI2oGso3lmRPy81fFYa0m6jayj+ZutjqWXuWbRwSLiCrKaRi3DTJtK0p8pG+tf9hu4pBOULdkwguw5iewbXNtJz6fnmiGaRdLbJe2bmqFmkQ1h7blv8u3Go6E6XERcVXmv1omIW6iuE/AtZO3cOwErgVMj4g+NjG2oIqJnOjVb5ACy5q/dyEaF/VVEbGxtSOZmKDMzq8jNUGZmVpGThZmZVdS1fRZjxoyJvr6+VodhZtZR7rjjjscjYmxhedcmi76+PpYtW9bqMMzMOoqkgWLlboYyM7OKnCzMzKwiJwszM6vIycLMzCpysjAzs4qcLMzMusCi5Yvou6SPHS7agb5L+li0fFHlB9Wga4fOmpn1ikXLFzH7h7N57oXnABjYMsDsH84GYObBM+tyDtcszMw63Lyl87YlikHPvfAc85bOq9s5nCzMzDrcui3FL2dTqnwonCzMzDrcpFGTaiofCicLM7MON3/afEbuOPIVZSN3HMn8afPrdg4nCzOzDjfz4JksOHkBk0dNRojJoyaz4OQFdevchi6++FF/f394IUEz63SLli9i3tJ5rNuyjkmjJjF/2vy6JoFCku6IiP7CctcszMyarNo5EYNDYge2DBDEtiGx9Z5DUQ0nCzOzJqolATRjSGy1nCzMzJqolgTQjCGx1XKyMDNroloSQDOGxFbLycLMrIlqSQDNGBJbLScLM7MmqiUBNGNIbLU8dNbMrMmaPRy2FqWGzjpZmJnZNp5nYWZmQ+ZkYWZmFTlZmJlZRU4WZmZ10uhLm7ZSw5KFpCskbZJ0b5FtfycpJI3Jlc2VtFrSKkkn5MoPl7Q8bfuKJDUqZjOzoWqndZwaoZE1i4XAiYWFkiYC7wTW5coOBGYAU9NjLpU0LG2+DJgNTEk/rzqmmVmrtdM6To3QsGQREb8Eniyy6cvAJ4H8mN3pwDUR8XxErAFWA0dIGgfsERG3RjbG91vAqY2K2cxsqNppHadGaGqfhaRTgIcj4p6CTeOB9bn7G1LZ+HS7sNzMrK200zpOjdC0ZCFpJDAP+HSxzUXKokx5qXPMlrRM0rLNmzcPLVAzsyFop3WcGqGZNYvXAfsD90haC0wA7pS0L1mNYWJu3wnAI6l8QpHyoiJiQUT0R0T/2LFj6xy+mVlp7bSOUyMMb9aJImI5sM/g/ZQw+iPicUlLgO9I+hKwH1lH9u0RsVXSM5KOAm4DzgS+2qyYzcxqWcdp5sEzuyY5FGrk0NmrgVuBAyRtkHROqX0jYgWwGFgJ3ACcGxFb0+aPAJeTdXo/CFzfqJjNzPK6fThsLbyQoJlZCX2X9DGwZeBV5ZNHTWbtnLXND6gJvJCgmVmNun04bC2cLMzMSuj24bC1cLIwMyuh24fD1sLJwsyshG4fDlsLd3Cbmdk27uA2M7Mhc7IwM7OKnCzMrCd184WKGqFpy32YmbWLwZnZg9efGJyZDfRk53U1XLMws57T7RcqagQnCzPrOZ6ZXTsnCzPrOZ6ZXTsnCzPrOZ6ZXTsnCzPrGtWOcPLM7Np5BreZdYXCEU6Q1RacBGrjGdxm1tU8wqmxnCzMrCt4hFNjOVmYWVfwCKfGcrIws67gEU6N5WRhZl3BI5way6OhzKztLVq+iHlL57FuyzomjZrE/GnznQQapNRoKC8kaGZtzYv+tQc3Q5lZS1Q7gc5DYtuDaxZm1nS11BY8JLY9uGZhZk1XS23BQ2Lbg5OFmTVdLbUFD4ltD04WZtZ0tdQWPCS2PbjPwsyabv60+UUX/StVW5h58EwnhxZzzcLMms61hc7TsEl5kq4ATgI2RcRBqewLwMnAH4EHgbMj4um0bS5wDrAVOD8ifpLKDwcWArsAPwY+FlUE7Ul5Zma1a8US5QuBEwvKbgIOiohDgP8E5qbgDgRmAFPTYy6VNCw95jJgNjAl/RQe08zMGqxhySIifgk8WVB2Y0S8mO7+FpiQbk8HromI5yNiDbAaOELSOGCPiLg11Sa+BZzaqJjNzKy4VvZZfAC4Pt0eD6zPbduQysan24XlRUmaLWmZpGWbN2+uc7hmZr2rJclC0jzgRWBwfr+K7BZlyouKiAUR0R8R/WPHjt3+QM3MDGjB0FlJs8g6vqflOqo3ABNzu00AHknlE4qUm5lZEzW1ZiHpROBTwCkRkZ/rvwSYIWmEpP3JOrJvj4iNwDOSjpIk4EzgB82M2czMGlizkHQ1cAwwRtIG4EKy0U8jgJuyz35+GxEfjogVkhYDK8map86NiK3pUB/h5aGz1/NyP4eZmTWJL35kZmbbtGKehZn1oGqvU2GdxWtDmVnd+Kp23cs1CzOrG1/Vrns5WZhZRdU2Lfmqdt3LycLMyhpsWhrYMkAQ25qWiiUMX9WuezlZmFlZtTQt+ap23cvJwszKqqVpydep6F4eDWVmZU0aNYmBLQNFy4vxVe26k2sWZlaWm5YMnCzMelo1o5zctGTg5T7MelbhBDrIagxOBL3Ny32Y2St4Ap3VwsnCrEd5Ap3VwsnCrEd5Ap3VwsnCrEd5lJPVwsnCrENUuz5Ttft5lJPVwqOhzDpAtSOXPMLJtpdHQ5l1sGpHLnmEkzWKk4VZB6h25JJHOFmjOFmYdYBqRy55hJM1ipOFWQeoduSSRzhZozhZmHWAakcueYSTNYpHQ5mZ2TYeDWVmZkPmZGFmZhU5WZiZWUVOFmZmVpGThZmZVdSwZCHpCkmbJN2bKxst6SZJD6Tfe+W2zZW0WtIqSSfkyg+XtDxt+4okNSpmMzMrrmSykLRD7vYUSddKWinpocGfCsdeCJxYUHYBsDQipgBL030kHQjMAKamx1wqaVh6zGXAbGBK+ik8plnHqnaFWLNWK1ezOE/S2en2N4EFwJPAscBV6aekiPhl2j9vOnBlun0lcGqu/JqIeD4i1gCrgSMkjQP2iIhbI5sQ8q3cY8w62uAKsQNbBgiCgS0DzP7hbCcMa0vlksXXgL0lnQHsEhE3AhERayPiQrKkUavXRMRGsgNtBPZJ5eOB9bn9NqSy8el2YXlRkmZLWiZp2ebNm4cQnlnzeIVY6yQlk0VEvBQRXwQWAf8/NUs9nD6Q38PLH/T1UKwfIsqUFxURCyKiPyL6x44dW7fgzBrBK8RaJ6nYwZ2af+YAI4FPAEcBZwJnl3lYKY+lpiXS702pfAMwMbffBOCRVD6hSLlZx/MKsdZJqhoNFRH/ERHPRsQjEfGBiHhPRPxmCOdbAsxKt2cBP8iVz5A0QtL+ZB3Zt6emqmckHZVGQZ2Ze4xZR/MKsdZJhpfbKOmSiJgj6YcUaf6JiFPKPPZq4BhgjKQNwIXA54DFks4B1gGnpeOskLQYWAm8CJwbEVvToT5CNrJqF+D69GPW8QZXgp23dB7rtqxj0qhJzJ823yvEWlsqu+qspMMj4g5Jb88Vb+tLiIibGxzfkHnVWTOz2g111dkJks6NiJtTYvgC2ZDXb1LfDm6zruL5E9ZtyjZDAZ8kmyw3aCegH9iVLGF8t0FxmXWswfkTg8NiB+dPAG5iso5VqWaxU0Tk5z/cEhFPRMQ6soRhZgU8f8K6UaVksVf+TkScl7vriQxmRXj+hHWjSsniNkkfLCyU9CHg9saEZNbZPH/CulGlPouPA9+X9NfAnanscGAEXqPJrKj50+a/os8CPH/COl/ZZBERm4C3SjqWbEVYgB9FxM8aHplZh/L8CetGZedZdDLPszAzq91Q51mYmZk5WZhVyxPtrJdV6uA2MzzRzsw1C7MqeKKd9TonC7MqeKKd9TonC7MqeKKd9TonC7Mq+EJF1uucLMyqMPPgmSw4eQGTR01GiMmjJrPg5AXu3Lae4Ul51vMWLV/k2dZmSalJeR46az3NQ2LNquNmKOtK1U6g85BYs+q4ZmFdp5bagofEmlXHNQvrOrXUFjwk1qw6ThbWdWqpLXhIrFl1nCys69RSW/CQWLPqOFlYR6mm47rW2sLMg2eyds5aXrrwJdbOWetEYVaEk4V1jMGO64EtAwSxreO6MGG4tmBWf56UZx2j75I+BrYMvKp88qjJrJ2ztvkBmXUhXynPOp6HuZq1jpOFdQwPczVrnZYkC0kfl7RC0r2Srpa0s6TRkm6S9ED6vVdu/7mSVktaJemEVsRsredhrmat0/RkIWk8cD7QHxEHAcOAGcAFwNKImAIsTfeRdGDaPhU4EbhU0rBmx22t545rs9Zp1XIfw4FdJL0AjAQeAeYCx6TtVwK/AD4FTAeuiYjngTWSVgNHALc2OWZrAzMPnunkYNYCTa9ZRMTDwBeBdcBGYEtE3Ai8JiI2pn02Avukh4wH1ucOsSGVvYqk2ZKWSVq2efPmRj0FM7Oe04pmqL3Iagv7A/sBu0o6o9xDipQVHe8bEQsioj8i+seOHbv9wZqZGdCaDu7jgDURsTkiXgC+B7wVeEzSOID0e1PafwMwMff4CWTNVmZm1iStSBbrgKMkjZQkYBpwH7AEmJX2mQX8IN1eAsyQNELS/sAU4PYmx2xm1tOa3sEdEbdJuha4E3gRuAtYAOwGLJZ0DllCOS3tv0LSYmBl2v/ciNja7LjNzHqZl/uwlvM1sM3ah6/BbW3J18A26wxe7sMapprlxH0NbLPO4JqFNUS1NQYvDmjWGVyzsIaotsbgxQHNOoOThTVEtTUGLw5o1hmcLKwhqq0xeHFAs87gPgtriPnT5r+izwJK1xi8OKBZ+3PNwhrCNQaz7uJJeWZmto2vwW1mZkPmZGE1qWainZl1H3dwW9W8NIdZ73LNwqrmpTnMepeThVXNS3OY9S4nC6ual+Yw611OFlY1L81h1rucLKxqnmhn1rs8Kc/MzLbxpDwry/MnzKwcz7Mwz58ws4pcszDPnzCzipwszPMnzKwiJwvz/Akzq8jJwjx/wswqcrLoQNWOXKp2P8+fMLNKPM+iwxSOXIKsFlD44V7tfmZmeZ5n0SWqHbnkEU5mVk9OFh2m2pFLHuFkZvXUkmQhaU9J10q6X9J9kt4iabSkmyQ9kH7vldt/rqTVklZJOqEVMbeLakcueYSTmdVTq2oW/wTcEBFvAN4E3AdcACyNiCnA0nQfSQcCM4CpwInApZKGtSTqNlDtyCWPcDKzemp6spC0B3A08A2AiPhjRDwNTAeuTLtdCZyabk8HromI5yNiDbAaOKKZMbeTakcueYSTmdVT00dDSToUWACsJKtV3AF8DHg4IvbM7fdUROwl6WvAbyPi26n8G8D1EXFtkWPPBmYDTJo06fCBgYEGPxszs+7STqOhhgOHAZdFxJuB35OanEpQkbKiGS4iFkREf0T0jx07dvsjNTMzoDXJYgOwISJuS/evJUsej0kaB5B+b8rtPzH3+AnAI02K1czMaEGyiIhHgfWSDkhF08iapJYAs1LZLOAH6fYSYIakEZL2B6YAtzcxZDOznteq61l8FFgkaSfgIeBsssS1WNI5wDrgNICIWCFpMVlCeRE4NyK2tiZsM7Pe1JJkERF3A6/qQCGrZRTbfz7gMZ9mZi3iGdxtwpc1NbN25suqtgFf1tTM2p1rFm3Ai/6ZWbtzsmiwapqXvOifmbU7J4sGGmxeGtgyQBDbmpcKE4YX/TOzdudk0UDVNi950T8za3dOFg1UbfOSF/0zs3bn0VANNGnUJAa2vHoxw2LNSzMPnunkYGZtyzWLIah2ToSbl8ysWzhZ1KjaTmtw85KZdY+mX8+iWfr7+2PZsmV1P27fJX1Fm5Ymj5rM2jlr634+M7NmaqfrWXQ0z4kws17kZFEjz4kws17kZFEjd1qbWS9ysqiRO63NrBe5g9vMzLZxB7eZmQ2Zk4WZmVXkZGFmZhU5WZiZWUVOFjm+DraZWXFedTbxdbDNzEpzzSLxdbDNzEpzski85pOZWWlOFonXfDIzK83JIvGaT2ZmpTlZJF7zycysNK8NZWZm27Td2lCShkm6S9J16f5oSTdJeiD93iu371xJqyWtknRCq2I2M+tVrWyG+hhwX+7+BcDSiJgCLE33kXQgMAOYCpwIXCppWJNjNTPraS1JFpImAH8BXJ4rng5cmW5fCZyaK78mIp6PiDXAauCIJoVqZma0rmZxCfBJ4KVc2WsiYiNA+r1PKh8PrM/ttyGVmZlZkzR9uQ9JJwGbIuIOScdU85AiZUV75SXNBmanu89KWjWkIGEM8PgQH9tsnRQrdFa8nRQrdFa8nRQrdFa82xvr5GKFrVgb6m3AKZLeDewM7CHp28BjksZFxEZJ44BNaf8NwMTc4ycAjxQ7cEQsABZsb4CSlhUbDdCOOilW6Kx4OylW6Kx4OylW6Kx4GxVr05uhImJuREyIiD6yjuufRcQZwBJgVtptFvCDdHsJMEPSCEn7A1OA25sctplZT2unVWc/ByyWdA6wDjgNICJWSFoMrAReBM6NiK2tC9PMrPe0NFlExC+AX6TbTwDTSuw3H2jmuhvb3ZTVRJ0UK3RWvJ0UK3RWvJ0UK3RWvA2JtWtncJuZWf14bSgzM6vIycLMzCrq6WQhaWdJt0u6R9IKSRel8pLrVLVaLWtqtZqktZKWS7pb0rJU1s7x7inpWkn3S7pP0lvaMV5JB6TXdPDn/0ma046xDpL08fQ/dq+kq9P/XlvGK+ljKc4VkuaksraJVdIVkjZJujdX1vC19Xo6WQDPA8dGxJuAQ4ETJR1FiXWq2kRVa2q1kXdExKG5cd/tHO8/ATdExBuAN5G9zm0Xb0SsSq/pocDhwHPAv9OGsQJIGg+cD/RHxEHAMLJh820Xr6SDgA+SLSn0JuAkSVNor1gXkq2Tl9f4tfUiwj9ZJ/9I4E7gSGAVMC6VjwNWtTq+FMuE9EY4FrgulbVlrCmetcCYgrK2jBfYA1hDGvTR7vHm4jse+HU7x8rLS/aMJhuBeV2Ku+3iJRuyf3nu/v8iW5qorWIF+oB7c/eLxgfMBebm9vsJ8JahnLPXaxaDzTp3k80YvykibqP0OlWtdgnVr6nVDgK4UdIdaSkWaN94XwtsBr6Zmvkul7Qr7RvvoBnA1el2W8YaEQ8DXySbP7UR2BIRN9Ke8d4LHC1pb0kjgXeTrSDRjrHmNXxtvZ5PFhGxNbLq/ATgiFQNbTv5NbVaHUsN3hYRhwHvAs6VdHSrAypjOHAYcFlEvBn4PW3QLFKOpJ2AU4DvtjqWclL7+XRgf2A/YFdJZ7Q2quIi4j7g88BNwA3APWSTgTtV1WvrVdLzyWJQRDxNNkHwRNI6VQAF61S10uCaWmuBa4Bj82tqQVvFCkBEPJJ+byJrUz+C9o13A7Ah1SwBriVLHu0aL2RJ+M6IeCzdb9dYjwPWRMTmiHgB+B7wVto03oj4RkQcFhFHA08CD9CmseaUiq/qtfUq6elkIWmspD3T7V3I3tT3U3qdqpaJ2tfUailJu0raffA2WRv1vbRpvBHxKLBe0gGpaBrZEjNtGW9yOi83QUH7xroOOErSSEkie23vo03jlbRP+j0JeC/Za9yWseY0fm29VncotbiT6BDgLuB3ZB9kn07le5N1JD+Qfo9udawFcR/Dyx3cbRkrWR/APelnBTCvneNNsR0KLEvvh+8De7VrvGQDMp4ARuXK2jLWFNtFZF/E7gWuAka0a7zAr8i+KNwDTGu315YseW0EXiCrOZxTLj5gHvAgWSf4u4Z6Xi/3YWZmFfV0M5SZmVXHycLMzCpysjAzs4qcLMzMrCInC7M6kvTfJb2+Tsf6qKTd6nEss+3lZGFWhqStaWXXFcpWJ/6EpB3Stn5JX8ntey7wNHBBmltSy3nmpOUlBu9/BBgZEc+W2H+hpL8aynMyGwoPnTUrQ9KzEbFbur0P8B2yhfsurPN51pKtyvp4SkZnRcQVZfZfSDbX5tp6xmFWimsWZlWKbNmS2cB5yhyjl68rsmu6zsB/pIUIp6fysyR9T9IN6VoDFxceV9L5ZGsm/VzSzyPiJeDTksak7WdK+l2q2VyVe+jRkn4j6SHXMqzRhrc6ALNOEhEPpW/+hauOziNbguUDaQmZ2yX9NG07FHgz2fVTVkn6akSszx3zK5I+QXbtj8fzB5U0NR37banWMTq3eRzwZ8AbyJZ1cC3DGsbJwqx2xVbyPJ5soce/S/d3Bial20sjYguApJXAZF65bHQ5xwLXDiaRiHgyt+37qRayUtJranwOZjVxsjCrgaTXAlvJVvV8Y34T8JcRsapg/yPJahSDtlLb/50ovaT08wX7mTWM+yzMqiRpLPB14Gvx6pEhPwE+mlZVRdKbazz8M8DuRcqXAu+TtHc67ugi+5g1nGsWZuXtkq6kuCPZRXCuAr5UZL9/ILuS4e9SwlgLnFTDeRYA10vaGBHvGCyMiBWS5gM3S9pKtkryWbU/DbPt46GzZmZWkZuhzOpIUngYq3Uj1yzMzKwi1yzMzKwiJwszM6vIycLMzCpysjAzs4qcLMzMrCInCzMzq+i/ABMhyBipQVgzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array(df['Diện tích'])\n",
    "Y = np.array(df['Giá'])\n",
    "plt.plot(x, Y,'go')\n",
    "plt.xlabel('Diện tích')\n",
    "plt.ylabel('Giá')\n",
    "plt.title('Quan hệ giữa diện tích nhà và giá nhà')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5aa52d",
   "metadata": {},
   "source": [
    "### Implement thuật toán với bài toán/dữ liệu trên "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "04aa7b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(torch.nn.Module): \n",
    "    def __init__(self):\n",
    "        super(LinearRegression, self).__init__() \n",
    "        self.linear = torch.nn.Linear(1, 1, bias = True) # bias is default True\n",
    "\n",
    "    def forward(self, x):\n",
    "        y_pred = self.linear(x)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3bf902a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model = LinearRegression()\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6a3023c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBuildIn(model, x, y, _iter, lr):\n",
    "    loss_list = []\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(our_model.parameters(), lr = lr) \n",
    "    \n",
    "    for i in range(_iter):\n",
    "        # Clear gradient buffers because we don't want any gradient from previous epoch to carry forward, dont want to cummulate gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # get output from the model, given the inputs\n",
    "        y_pred = model(x)\n",
    "\n",
    "        # get loss for the predicted output\n",
    "        loss = criterion(y_pred, y)\n",
    "        print(loss)\n",
    "        loss_list.append(loss.item())\n",
    "        # get gradients w.r.t to parameters\n",
    "        loss.backward()\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        print('Iter {}, loss {}'.format(i, loss.item()))\n",
    "        \n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4bf02084",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(df['Diện tích']).reshape([30,1]).astype(np.float32)\n",
    "Y = np.array(df['Giá']).reshape([30,1]).astype(np.float32)\n",
    "\n",
    "x = torch.from_numpy(x)\n",
    "Y = torch.from_numpy(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8cc74d",
   "metadata": {},
   "source": [
    "### Chỉnh learning rate cho dữ liệu trên, chọn 1 learning rate lớn bị overshoot, 1 learning vừa, và 1 learning rate nhỏ. Với mỗi learning rate, vẽ đồ thị loss tương ứng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96aef704",
   "metadata": {},
   "source": [
    "### Learning rate vừa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "36ef3904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1022534.2500, grad_fn=<MseLossBackward0>)\n",
      "Iter 0, loss 1022534.25\n",
      "tensor(840771.7500, grad_fn=<MseLossBackward0>)\n",
      "Iter 1, loss 840771.75\n",
      "tensor(691326.8125, grad_fn=<MseLossBackward0>)\n",
      "Iter 2, loss 691326.8125\n",
      "tensor(568453.1875, grad_fn=<MseLossBackward0>)\n",
      "Iter 3, loss 568453.1875\n",
      "tensor(467426.7188, grad_fn=<MseLossBackward0>)\n",
      "Iter 4, loss 467426.71875\n",
      "tensor(384362.8750, grad_fn=<MseLossBackward0>)\n",
      "Iter 5, loss 384362.875\n",
      "tensor(316067.7812, grad_fn=<MseLossBackward0>)\n",
      "Iter 6, loss 316067.78125\n",
      "tensor(259915.6406, grad_fn=<MseLossBackward0>)\n",
      "Iter 7, loss 259915.640625\n",
      "tensor(213747.3594, grad_fn=<MseLossBackward0>)\n",
      "Iter 8, loss 213747.359375\n",
      "tensor(175787.8906, grad_fn=<MseLossBackward0>)\n",
      "Iter 9, loss 175787.890625\n",
      "tensor(144577.5781, grad_fn=<MseLossBackward0>)\n",
      "Iter 10, loss 144577.578125\n",
      "tensor(118916.5391, grad_fn=<MseLossBackward0>)\n",
      "Iter 11, loss 118916.5390625\n",
      "tensor(97818.0703, grad_fn=<MseLossBackward0>)\n",
      "Iter 12, loss 97818.0703125\n",
      "tensor(80470.8750, grad_fn=<MseLossBackward0>)\n",
      "Iter 13, loss 80470.875\n",
      "tensor(66208.0625, grad_fn=<MseLossBackward0>)\n",
      "Iter 14, loss 66208.0625\n",
      "tensor(54481.1758, grad_fn=<MseLossBackward0>)\n",
      "Iter 15, loss 54481.17578125\n",
      "tensor(44839.3281, grad_fn=<MseLossBackward0>)\n",
      "Iter 16, loss 44839.328125\n",
      "tensor(36911.8203, grad_fn=<MseLossBackward0>)\n",
      "Iter 17, loss 36911.8203125\n",
      "tensor(30393.8125, grad_fn=<MseLossBackward0>)\n",
      "Iter 18, loss 30393.8125\n",
      "tensor(25034.7207, grad_fn=<MseLossBackward0>)\n",
      "Iter 19, loss 25034.720703125\n",
      "tensor(20628.5020, grad_fn=<MseLossBackward0>)\n",
      "Iter 20, loss 20628.501953125\n",
      "tensor(17005.6895, grad_fn=<MseLossBackward0>)\n",
      "Iter 21, loss 17005.689453125\n",
      "tensor(14027.0283, grad_fn=<MseLossBackward0>)\n",
      "Iter 22, loss 14027.0283203125\n",
      "tensor(11577.9619, grad_fn=<MseLossBackward0>)\n",
      "Iter 23, loss 11577.9619140625\n",
      "tensor(9564.3564, grad_fn=<MseLossBackward0>)\n",
      "Iter 24, loss 9564.3564453125\n",
      "tensor(7908.7559, grad_fn=<MseLossBackward0>)\n",
      "Iter 25, loss 7908.755859375\n",
      "tensor(6547.5249, grad_fn=<MseLossBackward0>)\n",
      "Iter 26, loss 6547.52490234375\n",
      "tensor(5428.3311, grad_fn=<MseLossBackward0>)\n",
      "Iter 27, loss 5428.3310546875\n",
      "tensor(4508.1313, grad_fn=<MseLossBackward0>)\n",
      "Iter 28, loss 4508.13134765625\n",
      "tensor(3751.5442, grad_fn=<MseLossBackward0>)\n",
      "Iter 29, loss 3751.544189453125\n",
      "tensor(3129.4736, grad_fn=<MseLossBackward0>)\n",
      "Iter 30, loss 3129.4736328125\n",
      "tensor(2618.0105, grad_fn=<MseLossBackward0>)\n",
      "Iter 31, loss 2618.010498046875\n",
      "tensor(2197.4849, grad_fn=<MseLossBackward0>)\n",
      "Iter 32, loss 2197.48486328125\n",
      "tensor(1851.7271, grad_fn=<MseLossBackward0>)\n",
      "Iter 33, loss 1851.72705078125\n",
      "tensor(1567.4489, grad_fn=<MseLossBackward0>)\n",
      "Iter 34, loss 1567.4488525390625\n",
      "tensor(1333.7134, grad_fn=<MseLossBackward0>)\n",
      "Iter 35, loss 1333.71337890625\n",
      "tensor(1141.5356, grad_fn=<MseLossBackward0>)\n",
      "Iter 36, loss 1141.53564453125\n",
      "tensor(983.5269, grad_fn=<MseLossBackward0>)\n",
      "Iter 37, loss 983.5269165039062\n",
      "tensor(853.6122, grad_fn=<MseLossBackward0>)\n",
      "Iter 38, loss 853.6122436523438\n",
      "tensor(746.7994, grad_fn=<MseLossBackward0>)\n",
      "Iter 39, loss 746.7993774414062\n",
      "tensor(658.9720, grad_fn=<MseLossBackward0>)\n",
      "Iter 40, loss 658.9720458984375\n",
      "tensor(586.7650, grad_fn=<MseLossBackward0>)\n",
      "Iter 41, loss 586.7649536132812\n",
      "tensor(527.3956, grad_fn=<MseLossBackward0>)\n",
      "Iter 42, loss 527.3956298828125\n",
      "tensor(478.5822, grad_fn=<MseLossBackward0>)\n",
      "Iter 43, loss 478.5821838378906\n",
      "tensor(438.4492, grad_fn=<MseLossBackward0>)\n",
      "Iter 44, loss 438.44921875\n",
      "tensor(405.4495, grad_fn=<MseLossBackward0>)\n",
      "Iter 45, loss 405.4494934082031\n",
      "tensor(378.3175, grad_fn=<MseLossBackward0>)\n",
      "Iter 46, loss 378.3175354003906\n",
      "tensor(356.0091, grad_fn=<MseLossBackward0>)\n",
      "Iter 47, loss 356.0091247558594\n",
      "tensor(337.6689, grad_fn=<MseLossBackward0>)\n",
      "Iter 48, loss 337.66888427734375\n",
      "tensor(322.5889, grad_fn=<MseLossBackward0>)\n",
      "Iter 49, loss 322.5888977050781\n",
      "tensor(310.1891, grad_fn=<MseLossBackward0>)\n",
      "Iter 50, loss 310.1890563964844\n",
      "tensor(299.9949, grad_fn=<MseLossBackward0>)\n",
      "Iter 51, loss 299.9949035644531\n",
      "tensor(291.6132, grad_fn=<MseLossBackward0>)\n",
      "Iter 52, loss 291.6131591796875\n",
      "tensor(284.7232, grad_fn=<MseLossBackward0>)\n",
      "Iter 53, loss 284.7231750488281\n",
      "tensor(279.0563, grad_fn=<MseLossBackward0>)\n",
      "Iter 54, loss 279.05633544921875\n",
      "tensor(274.3981, grad_fn=<MseLossBackward0>)\n",
      "Iter 55, loss 274.3981018066406\n",
      "tensor(270.5685, grad_fn=<MseLossBackward0>)\n",
      "Iter 56, loss 270.5684509277344\n",
      "tensor(267.4185, grad_fn=<MseLossBackward0>)\n",
      "Iter 57, loss 267.4185485839844\n",
      "tensor(264.8297, grad_fn=<MseLossBackward0>)\n",
      "Iter 58, loss 264.8297119140625\n",
      "tensor(262.7002, grad_fn=<MseLossBackward0>)\n",
      "Iter 59, loss 262.7002258300781\n",
      "tensor(260.9500, grad_fn=<MseLossBackward0>)\n",
      "Iter 60, loss 260.949951171875\n",
      "tensor(259.5101, grad_fn=<MseLossBackward0>)\n",
      "Iter 61, loss 259.5101318359375\n",
      "tensor(258.3272, grad_fn=<MseLossBackward0>)\n",
      "Iter 62, loss 258.32720947265625\n",
      "tensor(257.3542, grad_fn=<MseLossBackward0>)\n",
      "Iter 63, loss 257.354248046875\n",
      "tensor(256.5546, grad_fn=<MseLossBackward0>)\n",
      "Iter 64, loss 256.5545959472656\n",
      "tensor(255.8968, grad_fn=<MseLossBackward0>)\n",
      "Iter 65, loss 255.89675903320312\n",
      "tensor(255.3551, grad_fn=<MseLossBackward0>)\n",
      "Iter 66, loss 255.35507202148438\n",
      "tensor(254.9109, grad_fn=<MseLossBackward0>)\n",
      "Iter 67, loss 254.9109344482422\n",
      "tensor(254.5452, grad_fn=<MseLossBackward0>)\n",
      "Iter 68, loss 254.545166015625\n",
      "tensor(254.2449, grad_fn=<MseLossBackward0>)\n",
      "Iter 69, loss 254.244873046875\n",
      "tensor(253.9978, grad_fn=<MseLossBackward0>)\n",
      "Iter 70, loss 253.99781799316406\n",
      "tensor(253.7946, grad_fn=<MseLossBackward0>)\n",
      "Iter 71, loss 253.79457092285156\n",
      "tensor(253.6273, grad_fn=<MseLossBackward0>)\n",
      "Iter 72, loss 253.62734985351562\n",
      "tensor(253.4897, grad_fn=<MseLossBackward0>)\n",
      "Iter 73, loss 253.4897003173828\n",
      "tensor(253.3766, grad_fn=<MseLossBackward0>)\n",
      "Iter 74, loss 253.37661743164062\n",
      "tensor(253.2840, grad_fn=<MseLossBackward0>)\n",
      "Iter 75, loss 253.28396606445312\n",
      "tensor(253.2078, grad_fn=<MseLossBackward0>)\n",
      "Iter 76, loss 253.2078094482422\n",
      "tensor(253.1448, grad_fn=<MseLossBackward0>)\n",
      "Iter 77, loss 253.14479064941406\n",
      "tensor(253.0934, grad_fn=<MseLossBackward0>)\n",
      "Iter 78, loss 253.09341430664062\n",
      "tensor(253.0506, grad_fn=<MseLossBackward0>)\n",
      "Iter 79, loss 253.05064392089844\n",
      "tensor(253.0159, grad_fn=<MseLossBackward0>)\n",
      "Iter 80, loss 253.01585388183594\n",
      "tensor(252.9870, grad_fn=<MseLossBackward0>)\n",
      "Iter 81, loss 252.98695373535156\n",
      "tensor(252.9631, grad_fn=<MseLossBackward0>)\n",
      "Iter 82, loss 252.963134765625\n",
      "tensor(252.9439, grad_fn=<MseLossBackward0>)\n",
      "Iter 83, loss 252.9439239501953\n",
      "tensor(252.9279, grad_fn=<MseLossBackward0>)\n",
      "Iter 84, loss 252.92794799804688\n",
      "tensor(252.9150, grad_fn=<MseLossBackward0>)\n",
      "Iter 85, loss 252.9149932861328\n",
      "tensor(252.9045, grad_fn=<MseLossBackward0>)\n",
      "Iter 86, loss 252.9044952392578\n",
      "tensor(252.8954, grad_fn=<MseLossBackward0>)\n",
      "Iter 87, loss 252.89540100097656\n",
      "tensor(252.8881, grad_fn=<MseLossBackward0>)\n",
      "Iter 88, loss 252.88809204101562\n",
      "tensor(252.8821, grad_fn=<MseLossBackward0>)\n",
      "Iter 89, loss 252.88211059570312\n",
      "tensor(252.8770, grad_fn=<MseLossBackward0>)\n",
      "Iter 90, loss 252.87704467773438\n",
      "tensor(252.8729, grad_fn=<MseLossBackward0>)\n",
      "Iter 91, loss 252.87286376953125\n",
      "tensor(252.8697, grad_fn=<MseLossBackward0>)\n",
      "Iter 92, loss 252.86965942382812\n",
      "tensor(252.8662, grad_fn=<MseLossBackward0>)\n",
      "Iter 93, loss 252.8662109375\n",
      "tensor(252.8642, grad_fn=<MseLossBackward0>)\n",
      "Iter 94, loss 252.86422729492188\n",
      "tensor(252.8630, grad_fn=<MseLossBackward0>)\n",
      "Iter 95, loss 252.86302185058594\n",
      "tensor(252.8616, grad_fn=<MseLossBackward0>)\n",
      "Iter 96, loss 252.86155700683594\n",
      "tensor(252.8601, grad_fn=<MseLossBackward0>)\n",
      "Iter 97, loss 252.86007690429688\n",
      "tensor(252.8588, grad_fn=<MseLossBackward0>)\n",
      "Iter 98, loss 252.8588104248047\n",
      "tensor(252.8580, grad_fn=<MseLossBackward0>)\n",
      "Iter 99, loss 252.85801696777344\n",
      "tensor(252.8573, grad_fn=<MseLossBackward0>)\n",
      "Iter 100, loss 252.85726928710938\n",
      "tensor(252.8565, grad_fn=<MseLossBackward0>)\n",
      "Iter 101, loss 252.85650634765625\n",
      "tensor(252.8555, grad_fn=<MseLossBackward0>)\n",
      "Iter 102, loss 252.85548400878906\n",
      "tensor(252.8555, grad_fn=<MseLossBackward0>)\n",
      "Iter 103, loss 252.8555145263672\n",
      "tensor(252.8556, grad_fn=<MseLossBackward0>)\n",
      "Iter 104, loss 252.8556365966797\n",
      "tensor(252.8553, grad_fn=<MseLossBackward0>)\n",
      "Iter 105, loss 252.8553009033203\n",
      "tensor(252.8550, grad_fn=<MseLossBackward0>)\n",
      "Iter 106, loss 252.85499572753906\n",
      "tensor(252.8545, grad_fn=<MseLossBackward0>)\n",
      "Iter 107, loss 252.8545379638672\n",
      "tensor(252.8543, grad_fn=<MseLossBackward0>)\n",
      "Iter 108, loss 252.85426330566406\n",
      "tensor(252.8545, grad_fn=<MseLossBackward0>)\n",
      "Iter 109, loss 252.85447692871094\n",
      "tensor(252.8540, grad_fn=<MseLossBackward0>)\n",
      "Iter 110, loss 252.85400390625\n",
      "tensor(252.8538, grad_fn=<MseLossBackward0>)\n",
      "Iter 111, loss 252.85377502441406\n",
      "tensor(252.8545, grad_fn=<MseLossBackward0>)\n",
      "Iter 112, loss 252.85446166992188\n",
      "tensor(252.8543, grad_fn=<MseLossBackward0>)\n",
      "Iter 113, loss 252.85430908203125\n",
      "tensor(252.8537, grad_fn=<MseLossBackward0>)\n",
      "Iter 114, loss 252.8536834716797\n",
      "tensor(252.8538, grad_fn=<MseLossBackward0>)\n",
      "Iter 115, loss 252.8538055419922\n",
      "tensor(252.8541, grad_fn=<MseLossBackward0>)\n",
      "Iter 116, loss 252.8540802001953\n",
      "tensor(252.8536, grad_fn=<MseLossBackward0>)\n",
      "Iter 117, loss 252.85357666015625\n",
      "tensor(252.8533, grad_fn=<MseLossBackward0>)\n",
      "Iter 118, loss 252.8533172607422\n",
      "tensor(252.8532, grad_fn=<MseLossBackward0>)\n",
      "Iter 119, loss 252.8532257080078\n",
      "tensor(252.8533, grad_fn=<MseLossBackward0>)\n",
      "Iter 120, loss 252.85333251953125\n",
      "tensor(252.8538, grad_fn=<MseLossBackward0>)\n",
      "Iter 121, loss 252.85379028320312\n",
      "tensor(252.8537, grad_fn=<MseLossBackward0>)\n",
      "Iter 122, loss 252.85365295410156\n",
      "tensor(252.8538, grad_fn=<MseLossBackward0>)\n",
      "Iter 123, loss 252.85382080078125\n",
      "tensor(252.8534, grad_fn=<MseLossBackward0>)\n",
      "Iter 124, loss 252.8534393310547\n",
      "tensor(252.8536, grad_fn=<MseLossBackward0>)\n",
      "Iter 125, loss 252.8535614013672\n",
      "tensor(252.8535, grad_fn=<MseLossBackward0>)\n",
      "Iter 126, loss 252.85353088378906\n",
      "tensor(252.8532, grad_fn=<MseLossBackward0>)\n",
      "Iter 127, loss 252.85324096679688\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 128, loss 252.8529815673828\n",
      "tensor(252.8537, grad_fn=<MseLossBackward0>)\n",
      "Iter 129, loss 252.8536834716797\n",
      "tensor(252.8536, grad_fn=<MseLossBackward0>)\n",
      "Iter 130, loss 252.8535614013672\n",
      "tensor(252.8533, grad_fn=<MseLossBackward0>)\n",
      "Iter 131, loss 252.85325622558594\n",
      "tensor(252.8531, grad_fn=<MseLossBackward0>)\n",
      "Iter 132, loss 252.85311889648438\n",
      "tensor(252.8532, grad_fn=<MseLossBackward0>)\n",
      "Iter 133, loss 252.8532257080078\n",
      "tensor(252.8533, grad_fn=<MseLossBackward0>)\n",
      "Iter 134, loss 252.8533172607422\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 135, loss 252.85299682617188\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 136, loss 252.8529815673828\n",
      "tensor(252.8532, grad_fn=<MseLossBackward0>)\n",
      "Iter 137, loss 252.85324096679688\n",
      "tensor(252.8535, grad_fn=<MseLossBackward0>)\n",
      "Iter 138, loss 252.853515625\n",
      "tensor(252.8531, grad_fn=<MseLossBackward0>)\n",
      "Iter 139, loss 252.8531036376953\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 140, loss 252.85301208496094\n",
      "tensor(252.8533, grad_fn=<MseLossBackward0>)\n",
      "Iter 141, loss 252.85325622558594\n",
      "tensor(252.8532, grad_fn=<MseLossBackward0>)\n",
      "Iter 142, loss 252.85317993164062\n",
      "tensor(252.8525, grad_fn=<MseLossBackward0>)\n",
      "Iter 143, loss 252.8525390625\n",
      "tensor(252.8528, grad_fn=<MseLossBackward0>)\n",
      "Iter 144, loss 252.8528289794922\n",
      "tensor(252.8533, grad_fn=<MseLossBackward0>)\n",
      "Iter 145, loss 252.85333251953125\n",
      "tensor(252.8532, grad_fn=<MseLossBackward0>)\n",
      "Iter 146, loss 252.8532257080078\n",
      "tensor(252.8529, grad_fn=<MseLossBackward0>)\n",
      "Iter 147, loss 252.85293579101562\n",
      "tensor(252.8528, grad_fn=<MseLossBackward0>)\n",
      "Iter 148, loss 252.85281372070312\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 149, loss 252.8529815673828\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 150, loss 252.85299682617188\n",
      "tensor(252.8525, grad_fn=<MseLossBackward0>)\n",
      "Iter 151, loss 252.85252380371094\n",
      "tensor(252.8526, grad_fn=<MseLossBackward0>)\n",
      "Iter 152, loss 252.85255432128906\n",
      "tensor(252.8531, grad_fn=<MseLossBackward0>)\n",
      "Iter 153, loss 252.8530731201172\n",
      "tensor(252.8530, grad_fn=<MseLossBackward0>)\n",
      "Iter 154, loss 252.85302734375\n",
      "tensor(252.8528, grad_fn=<MseLossBackward0>)\n",
      "Iter 155, loss 252.85281372070312\n",
      "tensor(252.8524, grad_fn=<MseLossBackward0>)\n",
      "Iter 156, loss 252.85240173339844\n",
      "tensor(252.8524, grad_fn=<MseLossBackward0>)\n",
      "Iter 157, loss 252.85240173339844\n",
      "tensor(252.8524, grad_fn=<MseLossBackward0>)\n",
      "Iter 158, loss 252.85240173339844\n",
      "tensor(252.8521, grad_fn=<MseLossBackward0>)\n",
      "Iter 159, loss 252.85206604003906\n",
      "tensor(252.8525, grad_fn=<MseLossBackward0>)\n",
      "Iter 160, loss 252.8524932861328\n",
      "tensor(252.8529, grad_fn=<MseLossBackward0>)\n",
      "Iter 161, loss 252.85289001464844\n",
      "tensor(252.8531, grad_fn=<MseLossBackward0>)\n",
      "Iter 162, loss 252.85305786132812\n",
      "tensor(252.8527, grad_fn=<MseLossBackward0>)\n",
      "Iter 163, loss 252.85267639160156\n",
      "tensor(252.8527, grad_fn=<MseLossBackward0>)\n",
      "Iter 164, loss 252.8527069091797\n",
      "tensor(252.8527, grad_fn=<MseLossBackward0>)\n",
      "Iter 165, loss 252.8527069091797\n",
      "tensor(252.8527, grad_fn=<MseLossBackward0>)\n",
      "Iter 166, loss 252.8527374267578\n",
      "tensor(252.8523, grad_fn=<MseLossBackward0>)\n",
      "Iter 167, loss 252.8523406982422\n",
      "tensor(252.8524, grad_fn=<MseLossBackward0>)\n",
      "Iter 168, loss 252.8523712158203\n",
      "tensor(252.8528, grad_fn=<MseLossBackward0>)\n",
      "Iter 169, loss 252.85281372070312\n",
      "tensor(252.8528, grad_fn=<MseLossBackward0>)\n",
      "Iter 170, loss 252.85279846191406\n",
      "tensor(252.8521, grad_fn=<MseLossBackward0>)\n",
      "Iter 171, loss 252.85211181640625\n",
      "tensor(252.8521, grad_fn=<MseLossBackward0>)\n",
      "Iter 172, loss 252.85214233398438\n",
      "tensor(252.8521, grad_fn=<MseLossBackward0>)\n",
      "Iter 173, loss 252.85214233398438\n",
      "tensor(252.8522, grad_fn=<MseLossBackward0>)\n",
      "Iter 174, loss 252.85218811035156\n",
      "tensor(252.8518, grad_fn=<MseLossBackward0>)\n",
      "Iter 175, loss 252.851806640625\n",
      "tensor(252.8518, grad_fn=<MseLossBackward0>)\n",
      "Iter 176, loss 252.85182189941406\n",
      "tensor(252.8523, grad_fn=<MseLossBackward0>)\n",
      "Iter 177, loss 252.85226440429688\n",
      "tensor(252.8526, grad_fn=<MseLossBackward0>)\n",
      "Iter 178, loss 252.8525848388672\n",
      "tensor(252.8522, grad_fn=<MseLossBackward0>)\n",
      "Iter 179, loss 252.85220336914062\n",
      "tensor(252.8520, grad_fn=<MseLossBackward0>)\n",
      "Iter 180, loss 252.85203552246094\n",
      "tensor(252.8520, grad_fn=<MseLossBackward0>)\n",
      "Iter 181, loss 252.85203552246094\n",
      "tensor(252.8521, grad_fn=<MseLossBackward0>)\n",
      "Iter 182, loss 252.85206604003906\n",
      "tensor(252.8517, grad_fn=<MseLossBackward0>)\n",
      "Iter 183, loss 252.85165405273438\n",
      "tensor(252.8517, grad_fn=<MseLossBackward0>)\n",
      "Iter 184, loss 252.85169982910156\n",
      "tensor(252.8521, grad_fn=<MseLossBackward0>)\n",
      "Iter 185, loss 252.85211181640625\n",
      "tensor(252.8522, grad_fn=<MseLossBackward0>)\n",
      "Iter 186, loss 252.85223388671875\n",
      "tensor(252.8518, grad_fn=<MseLossBackward0>)\n",
      "Iter 187, loss 252.85183715820312\n",
      "tensor(252.8519, grad_fn=<MseLossBackward0>)\n",
      "Iter 188, loss 252.85186767578125\n",
      "tensor(252.8519, grad_fn=<MseLossBackward0>)\n",
      "Iter 189, loss 252.85186767578125\n",
      "tensor(252.8519, grad_fn=<MseLossBackward0>)\n",
      "Iter 190, loss 252.8518829345703\n",
      "tensor(252.8515, grad_fn=<MseLossBackward0>)\n",
      "Iter 191, loss 252.85154724121094\n",
      "tensor(252.8515, grad_fn=<MseLossBackward0>)\n",
      "Iter 192, loss 252.85154724121094\n",
      "tensor(252.8520, grad_fn=<MseLossBackward0>)\n",
      "Iter 193, loss 252.8519744873047\n",
      "tensor(252.8520, grad_fn=<MseLossBackward0>)\n",
      "Iter 194, loss 252.85203552246094\n",
      "tensor(252.8517, grad_fn=<MseLossBackward0>)\n",
      "Iter 195, loss 252.85169982910156\n",
      "tensor(252.8517, grad_fn=<MseLossBackward0>)\n",
      "Iter 196, loss 252.85171508789062\n",
      "tensor(252.8517, grad_fn=<MseLossBackward0>)\n",
      "Iter 197, loss 252.85171508789062\n",
      "tensor(252.8517, grad_fn=<MseLossBackward0>)\n",
      "Iter 198, loss 252.85174560546875\n",
      "tensor(252.8514, grad_fn=<MseLossBackward0>)\n",
      "Iter 199, loss 252.8513641357422\n"
     ]
    }
   ],
   "source": [
    "loss_list_1 = trainBuildIn(our_model, x, Y, 200, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "09eb7051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ----- ----- ----- -----\n",
      "Prediction:\n",
      "linear.weight tensor([[15.0973]])\n",
      "linear.bias tensor([1.0934])\n"
     ]
    }
   ],
   "source": [
    "y_pred_bi = our_model(x).data.numpy()\n",
    "\n",
    "print(\"----- ----- ----- ----- -----\")\n",
    "print(\"Prediction:\")\n",
    "for name, param in our_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1c93d9b9",
   "metadata": {
    "hide_input": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()\n",
    "plt.plot(df['Diện tích'], df['Giá'], 'go', label='True data', alpha=0.5)\n",
    "plt.plot(df['Diện tích'], y_pred_bi, '--', label='Predictions', alpha=0.5)\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b46e15d",
   "metadata": {},
   "source": [
    "### Đồ thị hàm loss với epochs = 200, lr = 0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "09a1bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss_list_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d62e032a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list_1, 'r')\n",
    "plt.tight_layout()\n",
    "plt.grid('True', color='y')\n",
    "plt.xlabel(\"Epochs/Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9bb831",
   "metadata": {},
   "source": [
    "### Learning rate lớn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "12adad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_2 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5531c090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 0, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 1, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 2, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 3, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 4, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 5, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 6, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 7, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 8, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 9, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 10, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 11, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 12, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 13, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 14, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 15, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 16, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 17, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 18, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 19, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 20, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 21, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 22, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 23, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 24, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 25, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 26, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 27, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 28, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 29, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 30, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 31, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 32, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 33, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 34, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 35, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 36, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 37, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 38, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 39, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 40, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 41, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 42, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 43, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 44, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 45, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 46, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 47, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 48, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 49, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 50, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 51, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 52, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 53, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 54, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 55, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 56, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 57, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 58, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 59, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 60, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 61, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 62, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 63, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 64, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 65, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 66, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 67, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 68, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 69, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 70, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 71, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 72, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 73, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 74, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 75, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 76, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 77, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 78, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 79, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 80, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 81, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 82, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 83, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 84, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 85, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 86, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 87, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 88, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 89, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 90, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 91, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 92, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 93, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 94, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 95, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 96, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 97, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 98, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 99, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 100, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 101, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 102, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 103, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 104, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 105, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 106, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 107, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 108, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 109, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 110, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 111, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 112, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 113, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 114, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 115, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 116, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 117, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 118, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 119, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 120, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 121, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 122, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 123, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 124, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 125, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 126, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 127, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 128, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 129, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 130, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 131, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 132, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 133, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 134, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 135, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 136, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 137, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 138, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 139, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 140, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 141, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 142, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 143, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 144, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 145, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 146, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 147, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 148, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 149, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 150, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 151, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 152, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 153, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 154, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 155, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 156, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 157, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 158, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 159, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 160, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 161, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 162, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 163, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 164, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 165, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 166, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 167, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 168, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 169, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 170, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 171, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 172, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 173, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 174, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 175, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 176, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 177, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 178, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 179, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 180, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 181, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 182, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 183, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 184, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 185, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 186, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 187, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 188, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 189, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 190, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 191, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 192, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 193, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 194, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 195, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 196, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 197, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 198, loss 970558.6875\n",
      "tensor(970558.6875, grad_fn=<MseLossBackward0>)\n",
      "Iter 199, loss 970558.6875\n"
     ]
    }
   ],
   "source": [
    "loss_list_2 = trainBuildIn(our_model_2, x, Y, 200, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "53463220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ----- ----- ----- -----\n",
      "Prediction:\n",
      "linear.weight tensor([[0.6861]])\n",
      "linear.bias tensor([-0.0774])\n"
     ]
    }
   ],
   "source": [
    "y_pred_bi = our_model_2(x).data.numpy()\n",
    "\n",
    "print(\"----- ----- ----- ----- -----\")\n",
    "print(\"Prediction:\")\n",
    "for name, param in our_model_2.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e64fba5",
   "metadata": {},
   "source": [
    "### Đồ thị hàm loss với epochs = 200, lr = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c04be814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list_2, 'r')\n",
    "plt.tight_layout()\n",
    "plt.grid('True', color='y')\n",
    "plt.xlabel(\"Epochs/Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c99146",
   "metadata": {},
   "source": [
    "### Learning rate nhỏ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d3eb2643",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_3 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "2c1bdc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 0, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 1, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 2, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 3, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 4, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 5, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 6, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 7, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 8, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 9, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 10, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 11, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 12, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 13, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 14, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 15, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 16, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 17, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 18, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 19, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 20, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 21, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 22, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 23, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 24, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 25, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 26, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 27, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 28, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 29, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 30, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 31, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 32, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 33, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 34, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 35, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 36, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 37, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 38, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 39, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 40, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 41, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 42, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 43, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 44, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 45, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 46, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 47, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 48, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 49, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 50, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 51, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 52, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 53, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 54, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 55, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 56, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 57, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 58, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 59, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 60, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 61, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 62, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 63, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 64, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 65, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 66, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 67, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 68, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 69, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 70, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 71, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 72, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 73, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 74, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 75, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 76, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 77, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 78, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 79, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 80, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 81, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 82, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 83, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 84, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 85, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 86, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 87, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 88, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 89, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 90, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 91, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 92, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 93, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 94, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 95, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 96, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 97, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 98, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 99, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 100, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 101, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 102, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 103, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 104, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 105, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 106, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 107, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 108, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 109, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 110, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 111, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 112, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 113, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 114, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 115, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 116, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 117, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 118, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 119, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 120, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 121, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 122, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 123, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 124, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 125, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 126, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 127, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 128, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 129, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 130, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 131, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 132, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 133, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 134, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 135, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 136, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 137, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 138, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 139, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 140, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 141, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 142, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 143, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 144, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 145, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 146, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 147, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 148, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 149, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 150, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 151, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 152, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 153, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 154, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 155, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 156, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 157, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 158, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 159, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 160, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 161, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 162, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 163, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 164, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 165, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 166, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 167, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 168, loss 1057443.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 169, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 170, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 171, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 172, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 173, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 174, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 175, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 176, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 177, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 178, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 179, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 180, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 181, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 182, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 183, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 184, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 185, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 186, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 187, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 188, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 189, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 190, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 191, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 192, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 193, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 194, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 195, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 196, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 197, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 198, loss 1057443.125\n",
      "tensor(1057443.1250, grad_fn=<MseLossBackward0>)\n",
      "Iter 199, loss 1057443.125\n"
     ]
    }
   ],
   "source": [
    "loss_list_3 = trainBuildIn(our_model_3, x, Y, 200, 0.00000000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "01d685b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ----- ----- ----- -----\n",
      "Prediction:\n",
      "linear.weight tensor([[0.0465]])\n",
      "linear.bias tensor([0.4652])\n"
     ]
    }
   ],
   "source": [
    "y_pred_bi = our_model_3(x).data.numpy()\n",
    "\n",
    "print(\"----- ----- ----- ----- -----\")\n",
    "print(\"Prediction:\")\n",
    "for name, param in our_model_3.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6109d999",
   "metadata": {},
   "source": [
    "### Đồ thị hàm loss với epochs = 200, lr = 0.00000000000001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "242a350c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list_3, 'r')\n",
    "plt.tight_layout()\n",
    "plt.grid('True', color='y')\n",
    "plt.xlabel(\"Epochs/Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c63135",
   "metadata": {},
   "source": [
    "### Chia tập train/test tỉ lệ 80/20, tính các chỉ số MSE, RSME, MAE, MAPE trên tập test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5283b325",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "...     x, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "df604754",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 97.5862],\n",
       "        [ 87.9310],\n",
       "        [ 58.9655],\n",
       "        [ 30.0000],\n",
       "        [ 39.6552],\n",
       "        [ 68.6207],\n",
       "        [ 42.0690],\n",
       "        [ 61.3793],\n",
       "        [ 56.5517],\n",
       "        [ 83.1034],\n",
       "        [ 32.4138],\n",
       "        [ 34.8276],\n",
       "        [ 90.3448],\n",
       "        [ 37.2414],\n",
       "        [ 80.6897],\n",
       "        [ 92.7586],\n",
       "        [ 73.4483],\n",
       "        [100.0000],\n",
       "        [ 78.2759],\n",
       "        [ 46.8966],\n",
       "        [ 54.1379],\n",
       "        [ 63.7931],\n",
       "        [ 75.8621],\n",
       "        [ 44.4828]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0b68271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "our_model_4 = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e07bd926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 0, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 1, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 2, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 3, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 4, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 5, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 6, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 7, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 8, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 9, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 10, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 11, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 12, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 13, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 14, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 15, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 16, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 17, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 18, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 19, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 20, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 21, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 22, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 23, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 24, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 25, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 26, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 27, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 28, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 29, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 30, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 31, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 32, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 33, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 34, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 35, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 36, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 37, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 38, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 39, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 40, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 41, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 42, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 43, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 44, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 45, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 46, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 47, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 48, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 49, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 50, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 51, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 52, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 53, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 54, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 55, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 56, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 57, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 58, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 59, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 60, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 61, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 62, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 63, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 64, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 65, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 66, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 67, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 68, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 69, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 70, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 71, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 72, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 73, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 74, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 75, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 76, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 77, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 78, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 79, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 80, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 81, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 82, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 83, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 84, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 85, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 86, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 87, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 88, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 89, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 90, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 91, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 92, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 93, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 94, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 95, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 96, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 97, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 98, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 99, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 100, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 101, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 102, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 103, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 104, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 105, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 106, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 107, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 108, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 109, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 110, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 111, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 112, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 113, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 114, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 115, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 116, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 117, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 118, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 119, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 120, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 121, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 122, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 123, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 124, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 125, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 126, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 127, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 128, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 129, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 130, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 131, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 132, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 133, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 134, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 135, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 136, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 137, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 138, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 139, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 140, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 141, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 142, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 143, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 144, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 145, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 146, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 147, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 148, loss 960640.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 149, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 150, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 151, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 152, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 153, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 154, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 155, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 156, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 157, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 158, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 159, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 160, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 161, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 162, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 163, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 164, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 165, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 166, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 167, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 168, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 169, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 170, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 171, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 172, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 173, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 174, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 175, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 176, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 177, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 178, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 179, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 180, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 181, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 182, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 183, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 184, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 185, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 186, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 187, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 188, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 189, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 190, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 191, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 192, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 193, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 194, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 195, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 196, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 197, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 198, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 199, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 200, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 201, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 202, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 203, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 204, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 205, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 206, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 207, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 208, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 209, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 210, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 211, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 212, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 213, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 214, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 215, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 216, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 217, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 218, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 219, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 220, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 221, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 222, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 223, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 224, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 225, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 226, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 227, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 228, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 229, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 230, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 231, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 232, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 233, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 234, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 235, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 236, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 237, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 238, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 239, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 240, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 241, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 242, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 243, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 244, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 245, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 246, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 247, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 248, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 249, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 250, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 251, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 252, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 253, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 254, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 255, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 256, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 257, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 258, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 259, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 260, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 261, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 262, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 263, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 264, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 265, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 266, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 267, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 268, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 269, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 270, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 271, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 272, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 273, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 274, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 275, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 276, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 277, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 278, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 279, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 280, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 281, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 282, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 283, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 284, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 285, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 286, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 287, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 288, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 289, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 290, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 291, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 292, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 293, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 294, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 295, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 296, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 297, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 298, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 299, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 300, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 301, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 302, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 303, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 304, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 305, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 306, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 307, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 308, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 309, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 310, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 311, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 312, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 313, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 314, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 315, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 316, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 317, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 318, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 319, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 320, loss 960640.3125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 321, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 322, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 323, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 324, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 325, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 326, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 327, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 328, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 329, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 330, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 331, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 332, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 333, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 334, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 335, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 336, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 337, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 338, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 339, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 340, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 341, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 342, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 343, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 344, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 345, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 346, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 347, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 348, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 349, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 350, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 351, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 352, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 353, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 354, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 355, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 356, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 357, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 358, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 359, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 360, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 361, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 362, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 363, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 364, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 365, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 366, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 367, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 368, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 369, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 370, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 371, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 372, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 373, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 374, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 375, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 376, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 377, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 378, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 379, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 380, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 381, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 382, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 383, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 384, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 385, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 386, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 387, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 388, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 389, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 390, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 391, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 392, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 393, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 394, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 395, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 396, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 397, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 398, loss 960640.3125\n",
      "tensor(960640.3125, grad_fn=<MseLossBackward0>)\n",
      "Iter 399, loss 960640.3125\n"
     ]
    }
   ],
   "source": [
    "fn_loss_lst = trainBuildIn(our_model_4, X_train, y_train, 400, 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ffa013a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- ----- ----- ----- -----\n",
      "Prediction:\n",
      "linear.weight tensor([[15.0973]])\n",
      "linear.bias tensor([1.0934])\n"
     ]
    }
   ],
   "source": [
    "y_pred_bi_fn = our_model(y_test).data.numpy()\n",
    "\n",
    "print(\"----- ----- ----- ----- -----\")\n",
    "print(\"Prediction:\")\n",
    "for name, param in our_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2541283a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bi_fn = torch.from_numpy(y_pred_bi_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1ce5e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = criterion(y_pred_bi_fn, y_test)\n",
    "rmse = torch.sqrt(mse)\n",
    "mae = torch.mean(torch.abs(y_pred_bi_fn - y_test))\n",
    "mape = torch.mean(torch.abs((y_pred_bi_fn - y_test) / y_test)) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "749a6daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3519e+08) tensor(15335.8438) tensor(14884.1436) tensor(1409.8435)\n"
     ]
    }
   ],
   "source": [
    "print(mse, rmse, mae, mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e8939",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51b21e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
